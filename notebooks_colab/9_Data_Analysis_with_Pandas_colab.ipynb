{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colab ONLY!\n",
    "\u2757 This notebook is designed to run on Google Colab.   \n",
    "\ud83c\udf89 These top few cells should install the nescessary libraries needed and set you up to be able to run the rest of the notebook!\n",
    "\n",
    "You should already have a Google account ready to go!\n",
    "\n",
    "To bore you with details, these cells will:\n",
    "- Install needed packages which are not already installed Google Colab\n",
    "- Download the required data and extract it where it is needed\n",
    "\n",
    "### \ud83e\uddd9\u200d\u2640\ufe0f Wizards\n",
    "\ud83e\uddd9\u200d\u2642\ufe0f If you're a wizard, here's some info about colab you may want to know:\n",
    "- Each Colab notebook runs on its own temporary Linux virtual machine with its own filesystem.   \n",
    "- If your notebook is shutdown, this will delete the temporary instance - this is why you need to mount Google Drive\n",
    "- Colab seems to let you have about 3 notebook instances running at any time; each of these will be on their own unique VM"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Now ensure the data we need is in the correct place\n",
    "!wget --no-verbose --output-document data.tar.gz https://github.com/CurtinIDS/CIDS_Carpentries_Python/releases/download/stable/data.tar.gz\n",
    "!tar xf /content/data.tar.gz -C /content\n",
    "# Now list the contents of the data folder\n",
    "!echo \n",
    "!echo The data folder contains:\n",
    "!ls -al /content/data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell has been automatically inserted from build_scripts/colab_nb_builder.py\n",
    "# It should make this notebook google-colab compatible!\n",
    "\n!pip install -q --upgrade pip \n",
    "!pip install -q ipykernel\n",
    "!pip install -q numpy\n",
    "!pip install -q matplotlib\n",
    "!pip install -q pandas",
    "\n!echo All done! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIDS Carpentries Workshop - Episode 9 - Data Analysis with Pandas\n",
    "This lesson is adapted from the Data Carpentries [Data Analysis and Visualization in Python for Ecologists](https://datacarpentry.org/python-ecology-lesson/) lesson.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \u2753 Questions and Objectives\n",
    "What should you be able to answer by the end of this episode?\n",
    "\n",
    "### Questions\n",
    "- What is Pandas?\n",
    "- Why should I use Pandas to work with data?\n",
    "- How can I access specific data within my data set?\n",
    "- How can Python and Pandas help me to analyse my data?\n",
    "\n",
    "### Objectives\n",
    "- Describe what the Python Data Analysis Library (Pandas) is.\n",
    "- Load the Python Data Analysis Library (Pandas).\n",
    "- Use read_csv to read tabular data into Python.\n",
    "- Access and summarise data stored in a DataFame.\n",
    "- Perform basic mathematical operations and summary statistics on data in a Pandas DataFrame.\n",
    "- Manipulate and extract data using column headings and index locations.\n",
    "- Employ slicing to select sets of data from a DataFrame.\n",
    "- Employ label and integer-based indexing to select ranges of data in a dataframe.\n",
    "- Query / select a subset of data using a set of criteria using the following operators: ==, !=, >, <, >=, <=.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Our Data\n",
    "\n",
    "For this lesson, we will be using the Portal Teaching data, a subset of the data\n",
    "from Ernst et al\n",
    "[Long-term monitoring and experimental manipulation of a Chihuahuan Desert ecosystem near Portal, Arizona, USA](http://www.esapubs.org/archive/ecol/E090/118/default.htm)\n",
    "\n",
    "We will be using files from the [Portal Project Teaching Database](https://figshare.com/articles/Portal_Project_Teaching_Database/1314459).\n",
    "This section will use the `surveys.csv` file which can be found in `../data/`.\n",
    "\n",
    "We are studying the species and weight of animals caught in plots in our study\n",
    "area. The dataset is stored as a `.csv` file: each row holds information for a\n",
    "single animal, and the columns represent:\n",
    "\n",
    "| Column           | Description                        |\n",
    "|------------------|------------------------------------|\n",
    "| record_id        | Unique id for the observation      |\n",
    "| month            | month of observation               |\n",
    "| day              | day of observation                 |\n",
    "| year             | year of observation                |\n",
    "| plot             | ID of a particular plot            |\n",
    "| species          | 2-letter code                      |\n",
    "| sex              | sex of animal (\"M\", \"F\")           |\n",
    "| wgt              | weight of the animal in grams      |\n",
    "\n",
    "\n",
    "The first few rows of our first file look like this:\n",
    "\n",
    "```\n",
    "record_id,month,day,year,plot_id,species_id,sex,hindfoot_length,weight\n",
    "1,7,16,1977,2,NL,M,32,\n",
    "2,7,16,1977,3,NL,M,33,\n",
    "3,7,16,1977,2,DM,F,37,\n",
    "4,7,16,1977,7,DM,M,36,\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas in Python\n",
    "One of the best options for working with tabular data in Python is to use the\n",
    "[Python Data Analysis Library](http://pandas.pydata.org/) (a.k.a. Pandas). The\n",
    "Pandas library provides data structures, produces high quality plots with\n",
    "[matplotlib](http://matplotlib.org/) and integrates nicely with other libraries\n",
    "that use [NumPy](http://www.numpy.org/) (which is another Python library) arrays.\n",
    "\n",
    "Python doesn't load all of the libraries available to it by default. We have to\n",
    "add an `import` statement to our code in order to use library functions. To import\n",
    "a library, we use the syntax `import libraryName`. If we want to give the\n",
    "library a nickname to shorten the command, we can add `as nickNameHere`.  An\n",
    "example of importing the pandas library using the common nickname `pd` is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Pandas library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each time we call a function that's in a library, we use the syntax\n",
    "`LibraryName.FunctionName`. Adding the library name with a `.` before the\n",
    "function name tells Python where to find the function. In the example above, we\n",
    "have imported Pandas as `pd`. This means we don't have to type out `pandas` each\n",
    "time we call a Pandas function.\n",
    "\n",
    "A handy **Pandas cheatsheet** can be found [here](http://pandas.pydata.org/Pandas_Cheat_Sheet.pdf).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading CSV Data using Pandas\n",
    "We will begin by locating and reading our survey data which is in CSV format. We can use Pandas' `read_csv` function to pull the file directly into a [DataFrame](https://pandas.pydata.org/pandas-docs/stable/getting_started/dsintro.html#dataframe).\n",
    "\n",
    "### So What's a DataFrame?\n",
    "A DataFrame is a 2-dimensional data structure that can store data of different types (including characters, integers, floating point values, factors and more) in columns. It is similar to a spreadsheet or an SQL table or the `data.frame` in R. A DataFrame always has an index (0-based). An index refers to the position of an element in the data structure.\n",
    "\n",
    "Let\u2019s call the imported survey data `surveys_df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that pd.read_csv is used because we imported pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice when you assign the imported DataFrame to a variable, Python does not produce any output on the screen. We can view the value of the `surveys_df` object by typing its name into the Python command prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there were 35,549 rows parsed. Each row has 9 columns. The first column is the index of the DataFrame. The index is used to identify the position of the data, but it is not an actual column of the DataFrame. It looks like the `read_csv` function in Pandas read our file properly.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Our Species Survey Data\n",
    "\n",
    "Now, we can start exploring our data. First, let's check the data type of the data stored in `surveys_df` using the `type` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the type of surveys_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What kind of things does `surveys_df` contain? DataFrames conveniently has an attribute called `dtypes` which answers this by returning the data type for each column in our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the types within surveys_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the values in a column have the same data type. \n",
    "\n",
    "Recalling from the previous episode about Python data types. Pandas and base Python use slightly different names for data types.\n",
    "\n",
    "| Pandas Type | Native Python Type | Description |\n",
    "|-------------|--------------------|-------------|\n",
    "| object | string | The most general dtype. Will be assigned to your column if column has mixed types (numbers and strings). |\n",
    "| int64  | int | Numeric characters. 64 refers to the memory allocated to hold this character. |\n",
    "| float64 | float | Numeric characters with decimals. If a column contains numbers and NaNs(see below), pandas will default to float64, in case your missing value has a decimal. |\n",
    "| datetime64, timedelta[ns] | N/A (but see the [datetime](http://doc.python.org/2/library/datetime.html) module in Python's standard library) | Values meant to hold time data. Look into these for time series experiments. |\n",
    "\n",
    "For example, months have type `int64`, which is an integer. Weight and hindfoot_length have type `float64` which is a floating point value. The `object` type in species_id and sex doesn't have a very helpful name, but in this case it represents strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Ways to View DataFrame Objects in Python\n",
    "There are many ways to summarise and access the data stored in DataFrames, using attributes and methods provided by the DataFrame object.\n",
    "\n",
    "Let's try out a few.\n",
    "\n",
    "To access an attribute, use the DataFrame object name followed by the attribute `df_object.attribute`. Using the DataFrame `surveys_df` and attribute `columns`, an index of all the column names in the DataFrame can be access with `surveys_df.columns`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the column names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods are called in a similar fashion using the syntax `df_object.method()`. As an example, `surveys_df.head()` gets the first few rows in the DataFrame `surveys_df` using **the `head()` method**. With a method, we can supply extra information in the parenthesis to control behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the first few rows of the dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Statistics from Data in a Pandas DataFrame\n",
    "We've now read our data into Python. Next, let's perform some quick summary statistics to learn more about the data that we're working with. We might want to know how many animals were collected in each site, or how many of each species were caught. We can perform summary stats quickly using groups. But first, we need to figure out what we want to group by.\n",
    "\n",
    "Let's explore our data some further:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the column names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a list of all the species. The `pd.unique` function tells us all of the unique values in the `species_id` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the unique species ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's useful, but how would we identify the number of unique species in the data? We can use the `len()` function as before or `the .nunique()` function in Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the len() function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the .nunique() function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groups in Pandas\n",
    "We often want to calculate summary statistics grouped by subsets or attributes within fields of our data. For example, we might want to calculate the average weight of all individuals per site.\n",
    "\n",
    "We can calculate basic statistics for all records in a single column using the Pandas `.describe` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for the entire dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for the weight column\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also extract specific metrics if we wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Others?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we want to summarize by one or more variables, for example `sex`, we can use Pandas\u2019 `.groupby` method. Once we\u2019ve created a groupby DataFrame, we can quickly calculate summary statistics by a group of our choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by sex and assign to a variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas function describe will return descriptive stats including: mean, median, max, min, std and count for a particular column in the data. Pandas\u2019 describe function will only return summary values for columns containing numeric data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for all numeric columns by sex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the mean for each numeric column by sex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Quick and Easy Plotting using Pandas\n",
    "\n",
    "We can plot summary stats using Pandas too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure figures appear inline in our Ipython Notebook \n",
    "# (sometimes automatic, good to always include!)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a total_count variable that sums the 'record_id' values for each site\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Indexing and Slicing in Pandas\n",
    "We often want to work with subsets of a **DataFrame** object. There are different ways to accomplish this including: using labels (column headings), numeric ranges, or specific x,y index locations.\n",
    "\n",
    "We use square brackets `[]` to select a subset of a Python object. For example, we can select all data from a column named `species_id` from the `surveys_df` DataFrame by name. There are two ways to do this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Select a 'subset' of the data using the column name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Use the column name as an 'attribute'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a new object that contains only the data within the `species_id` column as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an object, surveys_species, that only contains the `species_id` column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass a list of column names too, as an index to select columns in that order. This is useful when we need to reorganise our data.\n",
    "\n",
    "**NOTE:** If a column name is not contained in the DataFrame, an exception (error) will be raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the species and plot_id columns from the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What happens if we flip the order?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What happens if you ask for a column that doesn't exist?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python tells us what type of error it is in the traceback, at the bottom it says KeyError: 'speciess' which means that speciess is not a valid column name (nor a valid key in the related Python data type dictionary).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing Subsets of Rows in Pandas\n",
    "Slicing using the `[]` operator selects a set of rows and/or columns from a DataFrame. To slice out a set of rows, you use the following syntax `data[start:stop]`. When slicing in Pandas, the start bound is included in the output. The stop bound is one step BEYOND the row you want to select. So if you want to select rows 0, 1 and 2; your code would look like this.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows 0, 1, 2 (row 3 is not selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first 5 rows (rows 0, 1, 2, 3, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the last row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Slicing Subsets of Rows and Columns in Python\n",
    "We can select specific ranges of our data in both the row and column directions using either label or integer-based indexing.\n",
    "- `loc`: *label* based indexing where you can refer to rows and columns by their name (which can be integers)\n",
    "- `iloc`: *integer* based indexing counting from 0\n",
    "\n",
    "To select a subset of rows **and** columns from our DataFrame, we can use the `iloc` method. For example, we can select month, day and year (columns 1, 2 and 3 if we start counting at 0), like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iloc[row slicing, column slicing]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we asked for a slice from 0:3. This yielded 3 rows of data. When you ask for 0:3, you are actually telling Python to start at index 0 and select rows 0, 1, 2 **up to but not including 3.**\n",
    "\n",
    "Let's explore some other ways to index and select subsets of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all columns for rows of index values 0 and 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select using column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting out of bounds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: Labels must be found in the DataFrame or you will get a `KeyError`.\n",
    "\n",
    "Indexing by labels `loc` differs from indexing by integers `iloc`. With `loc`, both the start bound and the stop bound are **inclusive**. When using `loc`, integers *can* be used, but the integers refer to the index label and not the position.  For example, using `loc` and selecting 1:4 will get a different result than using `iloc` to select rows 1:4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using `loc`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using `iloc`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also select a specific data value using a row and column location within the DataFrame and `iloc` indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dat.iloc[row, column]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that Python indexing begins at 0. So, the index location [2,6] selects the element that is 3 rows down and 7 columns over in the DataFrame.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting Data using Criteria\n",
    "We can also select a subset of our data using criteria. For example, we can select all rows that have a year value of 2002:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting rows where the year is 2002\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can select all rows that do not contain the year 2002:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting rows where the year is not 2002\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define sets of criteria too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting rows where the year is between 1980 and 1985\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## \ud83c\udfc6 Exercises\n",
    "\n",
    "### \u270f\ufe0f Exercise 1 : Pandas Attributes and Methods\n",
    "Using our DataFrame `surveys_df`, try out the attributes and methods to see what they return.\n",
    "1. `surveys_df.columns`\n",
    "2. `surveys_df.shape` - take a note of the output of `shape` - what format does it return the shape of the DataFrame in?\n",
    "3. `surveys_df.head(15)`\n",
    "4. `surveys_df.tail()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \u270f\ufe0f Exercise 2 : Summary Data\n",
    "1. How many recorded individuals are female `F` and how many male `M`?\n",
    "2. What happens when you group by two columns using the following syntax and then calculate mean values?\n",
    " - `grouped_data2 = surveys_df.groupby(['plot_id', 'sex'])`\n",
    " - `grouped_data2.mean()`\n",
    "3.  Summarize weight values for each site in your data. HINT: you can use the following syntax to only create summary statistics for one column in your data. by_`site['weight'].describe()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \u270f\ufe0f Exercise 3 : Selecting Data in Pandas\n",
    "1. What happens when you execute the following:\n",
    "    - `surveys_df[0:1]`\n",
    "    - `surveys_df[0]`\n",
    "    - `surveys_df[:4]`\n",
    "    - `surveys_df[:-4]`\n",
    "2. What happens when you call:\n",
    "    - `surveys_df.iloc[0:1]`\n",
    "    - `surveys_df.iloc[0]`\n",
    "    - `surveys_df.iloc[:4, :]`\n",
    "    - `surveys_df.iloc[0:4, 1:4]`\n",
    "    - `surveys_df.loc[0:4, 1:4]`\n",
    "\n",
    "How are the two sets of commands different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \u270f\ufe0f Exercise 4 : Queries using Criteria\n",
    "1. Select a subset of rows in the surveys_df DataFrame that contain data from the year 1999 and that contain weight values less than or equal to 8. How many rows did you end up with? What did your neighbor get?\n",
    "\n",
    "2. You can use the isin command in Python to query a DataFrame based upon a list of values as follows:\n",
    "```py\n",
    "surveys_df[surveys_df['species_id'].isin([listGoesHere])]\n",
    "```\n",
    "\n",
    "3. Experiment with other queries. Create a query that finds all rows with a weight value greater than or equal to 0.\n",
    "\n",
    "4. The ~ symbol in Python can be used to return the OPPOSITE of the selection that you specify. It is equivalent to is not in. Write a query that selects all rows with sex NOT equal to \u2018M\u2019 or \u2018F\u2019 in the \u201csurveys\u201d data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## \ud83d\udd11 Key Points\n",
    "- Libraries enable us to extend the functionality of Python.\n",
    "- Pandas is a popular library for working with data.\n",
    "- A Dataframe is a Pandas data structure that allows one to access data by column (name or index) or row.\n",
    "- Aggregating data using the groupby() function enables you to generate useful summaries of data quickly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}