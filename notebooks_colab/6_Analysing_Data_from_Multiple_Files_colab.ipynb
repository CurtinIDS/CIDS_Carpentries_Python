{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colab only\n",
    "‚ùó This notebook is designed to run on google colab.   \n",
    "üéâ These top few cells should install the nescesary libraries needed and set you up to be able to run the rest of the notebook!\n",
    "\n",
    "You should already have a google account ready to go!\n",
    "\n",
    "To bore you with details, these cells will:\n",
    "- Install needed packages which are not already installed google-colab\n",
    "- Download the needed data and extract it where it is needed\n",
    "\n",
    "### üßô‚Äç‚ôÄÔ∏è Wizards\n",
    "üßô‚Äç‚ôÇÔ∏è If you're a wizard, here's some info about colab you may want to know:\n",
    "- Each colab notebook runs on its own temporary linux virtual machine with its own filesystem.   \n",
    "- If your notebook is shutdown, this will delete the temporary instance - this is why you need to mount google drive\n",
    "- Colab seems to let you have about 3 notebook instances running at any time; each of these will be on their own unique VM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now ensure the data we need is in the correct place\n",
    "!wget --no-verbose --output-document data.zip https://github.com/CurtinIDS/CIDS_Carpentries_Python/releases/download/stable/data.tar.gz\n",
    "!unzip -o data.zip -d ../data\n",
    "# Now list the contents to make sure we see the 4 shapefile components (.dbf, .prj, .shp, and .shx)\n",
    "!echo \n",
    "!echo The data folder contents:\n",
    "!ls -al ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell has been automatically inserted from build_scripts/colab_nb_builder.py\n",
    "# It should make this notebook google-colab compatible!\n",
    "\n",
    "!pip install -q --upgrade pip \n",
    "!pip install -q ipykernel\n",
    "!pip install -q numpy\n",
    "!pip install -q matplotlib\n",
    "!pip install -q pandas\n",
    "!echo All done! Test below if it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIDS Carpentries Workshop - Episode 6 - Analysing Data from Multiple Files\n",
    "This lesson is adapted from the Software Carpentries [Programming with Python](https://swcarpentry.github.io/python-novice-inflammation/index.html) lesson.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ùì Questions and Objectives\n",
    "What should you be able to answer by the end of this episode?\n",
    "\n",
    "### Questions\n",
    "- How can I do the same operations on many different files?\n",
    "\n",
    "\n",
    "### Objectives\n",
    "- Use a library function to get a list of filenames that match a wildcard pattern.\n",
    "- Write a `for` loop to process multiple files.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final piece to processing our inflammation data, we need a way to get a list of all the files in our `data` directory whose names start with `inflammation-` and end with `.csv`. The following library will help us to achieve this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `glob` library contains a function, also called `glob`, that finds files and directories whose names match a pattern. We provide those patterns as strings: the character `*` matches zero or more characters, while `?` matches any one character.\n",
    "\n",
    "We can use this to get the names of all the CSV files in a directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the list of files in the data folder that start with inflammation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As these examples show, `glob.glob`'s result is a list of file and diretory paths in arbitrary order. This means we can loop over it to do something with each filename in turn.\n",
    "\n",
    "In our case, the \"something\" we want to do is generate a set of plots for each file in our inflammation dataset.\n",
    "\n",
    "If we want to start by analysing just the first three files in alphabetical order, we can use the `sorted` built-in function to generate a new sorted list from the `glob.glob` output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting and slicing the list of files in the data folder that start with inflammation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisiting the code from `Grouping Plots` in `3_Visualising_Tabular_Data`, we will use a `for` loop to generate subplots for the average, max and min for our files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Instantiating a for loop\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "\n",
    "    # Copying the code from the previous lesson\n",
    "    data = np.loadtxt(fname=filename, delimiter=',')\n",
    "\n",
    "    fig = plt.figure(figsize=(10.0, 3.0))\n",
    "\n",
    "    axes1= fig.add_subplot(1, 3, 1)\n",
    "    axes2= fig.add_subplot(1, 3, 2)\n",
    "    axes3= fig.add_subplot(1, 3, 3)\n",
    "\n",
    "    axes1.set_ylabel('average')\n",
    "    axes1.plot(np.mean(data, axis=0))\n",
    "\n",
    "    axes2.set_ylabel('max')\n",
    "    axes2.plot(np.amax(data, axis=0))\n",
    "\n",
    "    axes3.set_ylabel('min')\n",
    "    axes3.plot(np.amin(data, axis=0))\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots generated for the second clinical trial file loop very similar to the plots in the first file; their average plots show similar \"noisy\" rises and falls; their maxima plots show exactly the same linear rise and fall; and their minima plots show similar staircase structures.\n",
    "\n",
    "The third dataset shows much noisier average and maxima plots that are far less suspicious than the first two datasets, however the minima plot shows that the third dataset minima is consistently zero across every day of the trial. If we produce a heatmap for the third datafile, we see the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a heatmap of the third datafile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are zero values sporadically distributed across all patients and days of the clinical trial, suggesting that there were potential issues with data collection throughout the trial. In addition, we can see that the last patient in the study didn't have any inflammation flare-ups at all throughout the trial, suggesting that they many not even suffer from arthritis!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üèÜ Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úèÔ∏è Exercise 1 : Plotting Differences\n",
    "\n",
    "Plot the difference between the average inflamation reported in the first and second datasets (stored in `inflammation-01.csv` and `inflammation-02.csv`, correspondingly).\n",
    "i.e. the difference between the leftmost plots of the first two figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úèÔ∏è Exercise 2 : Generate Composite Statistics\n",
    "\n",
    "Use each of the files once to generate a dataset containing values averaged over all patients by completing the code inside the loop given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob.glob('../data/inflammation*.csv')\n",
    "composite_data = np.zeros((60, 40))\n",
    "for filename in filenames:\n",
    "    data = np.loadtxt(fname=filename, delimiter=',')\n",
    "    # sum each new file's data into composite_data as it's read\n",
    "# and then divide the composite_data by number of samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then use pyplot to generate average, max, and min for all patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10.0, 3.0))\n",
    "\n",
    "axes1 = fig.add_subplot(1, 3, 1)\n",
    "axes2 = fig.add_subplot(1, 3, 2)\n",
    "axes3 = fig.add_subplot(1, 3, 3)\n",
    "\n",
    "axes1.set_ylabel('average')\n",
    "axes1.plot(np.mean(composite_data, axis=0))\n",
    "\n",
    "axes2.set_ylabel('max')\n",
    "axes2.plot(np.amax(composite_data, axis=0))\n",
    "\n",
    "axes3.set_ylabel('min')\n",
    "axes3.plot(np.amin(composite_data, axis=0))\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "After spending some time investigating the heatmap and statistical plots, as well as doing the above exercises to plot differences between datasets and to generate composite patient statistics, we gain some insight into the twelve clinical trial datasets.\n",
    "\n",
    "The datasets appear to fall into two categories:\n",
    "1. seemingly \"ideal\" datasets that agree excellently with Dr. Maverick's claims, but displays suspicious maxima and minima (such as `inflammation-01.csv` and `inflammation-02.csv`)\n",
    "2. \"noisy\" datasets that somewhat agree with Dr. Maverick's claims, but show concerning data collection issues such as sporadic missing values and even an unsuitable candidate making it into the clinical trial.\n",
    "\n",
    "In fact, it appears that all three of the \"noisy\" datasets (`inflammation-03.csv`, `inflammation-08.csv`, and `inflammation-11.csv`) are identical down to the last value. Armed with this information, we confront Dr. Maverick about the suspicious data and duplicated files.\n",
    "\n",
    "Dr. Maverick has admitted to fabricating the clinical data for their drug trial. They did this after discovering that the initial trial had several issues, including unreliable data recording and poor participant selection. In order to prove the efficay of their drug, they created fake data. When asked for additional data, they attempted to generate more fake datasets, and also included the original poor-quality dataset several times in order to make the trials seem more realistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéâ Congratulations! We've investigated the inflammation data and proven that the datasets have been synthetically generated.\n",
    "\n",
    "But it would be a shame to throw away the synthetic datasets that have taught us so much already, so we'll forgive the imaginary Dr. Maverick and continue to use the data to learn how to program!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîë Key Points\n",
    "- Use `glob.glob(pattern)` to create a list of files whose names match a pattern.\n",
    "- Use `*` in a pattern to match zero or more characters, and `?` to match any single character.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
